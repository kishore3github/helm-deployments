# .github/workflows/main.yaml
name: Consolidated Deployment Workflow

on:
  push:
    branches:
      - main
    paths:
      - 'consolidated-deployments.yaml'
  workflow_dispatch:
    inputs:
      mode:
        description: 'Mode of operation'
        required: true
        default: 'sequential'
        type: choice
        options:
          - sequential
          - parallel

jobs:
  read-services:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Install yq and jq
        run: |
          sudo apt-get update
          sudo apt-get install -y jq
          sudo snap install yq

      - name: Read deployment.yaml and deploy sequentially
        env:
          GH_TOKEN: ${{ secrets.PERSONAL_ACCESS_TOKEN }}
          GITHUB_TOKEN: ${{ secrets.PERSONAL_ACCESS_TOKEN }}
          DRY_RUN: false
        run: |
            echo "GH_TOKEN: ${GH_TOKEN:-(not set)}"
            echo "GITHUB_TOKEN: ${GITHUB_TOKEN:-(not set)}"
            echo "GITHUB_REF_NAME: ${GITHUB_REF_NAME:-(not set)}"
            DRY_RUN="${{ env.DRY_RUN }}"
            echo "Reading services from consolidated-deployments.yaml"
            i=0

            # Example loop for groups (replace with your actual logic)
            for serviceGroup in $(cat consolidated-deployments.yaml | yq '.groups[] | @base64'); do
              echo "=== Deploying group $i in parallel ==="
              run_ids_file="run_ids_$i.txt"
              > "$run_ids_file"

              # Read all services in the group into an array
              mapfile -t services < <(echo "$serviceGroup" | base64 --decode | jq -c '.[]')

              pids=()
              for svc in "${services[@]}"; do
                (
                  name=$(echo "$svc" | jq -r '.name')
                  image=$(echo "$svc" | jq -r '.image')
                  ns=$(echo "$svc" | jq -r '.namespace')
                  flyway=$(echo "$svc" | jq -r '.flyway')

                  if [[ $name == "list-team" ]]; then
                    export workflow_name="reusable_cd.yaml"
                  elif [[ $name == "my-service" ]]; then
                    export workflow_name="reusable_cd_1.yaml"
                  else
                    export workflow_name="reusable_cd.yaml"
                  fi
                  echo "Triggering $name in namespace $ns with image $image and flyway=$flyway"
                  # Get list of current run IDs before triggering
                  before_ids=$(gh run list --workflow=$workflow_name --json databaseId -q '.[].databaseId')

                  gh workflow run $workflow_name \
                    -f service="$name" \
                    -f image_tag="$image" \
                    -f namespace="$ns" \
                    -f flyway="$flyway"

                  # Wait for a new run to appear
                  new_run_id=""
                  for attempt in {1..12}; do
                    sleep 5
                    after_ids=$(gh run list --workflow=$workflow_name --json databaseId -q '.[].databaseId')
                    new_run_id=$(comm -13 <(echo "$before_ids" | sort) <(echo "$after_ids" | sort) | tail -n1)
                    if [[ -n "$new_run_id" ]]; then
                      break
                    fi
                  done

                  if [[ -z "$new_run_id" ]]; then
                    echo "❌ Failed to get new run ID for $name"
                    exit 1
                  fi
                  echo "Run ID for $name in $ns: $new_run_id"
                  echo "$new_run_id" >> "$run_ids_file"
                ) &
                pids+=($!)
              done
              # Wait for all background triggers to finish
              for pid in "${pids[@]}"; do
                wait "$pid"
              done

              # Now watch all runs in parallel
              watch_pids=()
              while read -r id; do
                (
                  while true; do
                    status=$(gh run view "$id" --json status -q '.status')
                    conclusion=$(gh run view "$id" --json conclusion -q '.conclusion')
                    echo "Workflow $id status: $status / $conclusion"

                    if [[ "$status" == "completed" ]]; then
                      if [[ "$conclusion" == "success" ]]; then
                        echo "✅ Run $id succeeded"
                        break
                      else
                        echo "❌ Run $id failed or cancelled"
                        exit 1
                      fi
                    fi
                    sleep 10
                  done
                ) &
                watch_pids+=($!)
              done < "$run_ids_file"

              # Wait for all watches to finish
              for pid in "${watch_pids[@]}"; do
                wait "$pid"
              done

              rm -f "$run_ids_file"
              echo "✅ Group $i complete"
              ((i+=1))
            done

